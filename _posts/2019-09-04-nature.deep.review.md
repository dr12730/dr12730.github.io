---
title: 深度学习
date: 2019-09-04 21:26:11 +0800
description: 
image:      
    path: /assets/images/posts/2019-09-04-nature.deep.review/cover.jpg 
    thumbnail: /assets/images/posts/2019-09-04-nature.deep.review/thumb.jpg 
categories: 
    - ai
tags:
    - CV
---

机器学习技术推动了现代社会的许多方面：从网络搜索到社交网络上的内容过滤，再到电子商务网站上的推荐，它越来越多地出现在诸如相机和智能手机等消费品中。机器学习系统用于识别图像中的对象，将语音转换成文本，根据用户的兴趣匹配新闻条目、帖子或产品，并选择相关的搜索结果。这些应用程序越来越多地使用一种称为深度学习的技术。

传统的机器学习技术在处理原始形式的自然数据方面受到限制。几十年来，构造一个模式识别或机器学习系统需要仔细的工程设计和相当多的领域专业知识来设计一个特征提取器，将原始数据（如图像的像素值）转换成合适的内部表示或特征向量。学习子系统，通常是分类器，可以从中检测或分类输入中的模式。

表示学习是一组方法，允许机器输入原始数据，并自动发现检测或分类所需的表示。深度学习方法是具有多个表示层次的表示学习方法，通过组成简单但非线性的模块来获得，每个模块将一个层次上的表示（从原始输入开始）转换为一个更高、更抽象的层次上的表示。有了足够多这样的转换组合，就可以学习非常复杂的函数。对于分类任务，较高的表示层会放大输入的某些方面，这些方面对于区分和抑制不相关的变化非常重要。例如，图像以像素值数组的形式出现，第一层表示中的学习特征通常表示图像中特定方向和位置的边的存在或不存在。第二层通常通过定位边缘的特定排列来检测图案，而不考虑边缘位置的微小变化。第三层可以将图案组合成更大的组合，对应于熟悉对象的部分，随后的层将检测这些部分的组合对象。深度学习的关键是，这些特征层不是由人类工程师设计的：它们是使用通用学习过程从数据中学习的。

深度学习在解决多年来一直抵制人工智能社区最佳尝试的问题方面取得了重大进展。事实证明，它非常善于发现高维数据中复杂的结构，因此适用于科学、商业和政府的许多领域。除了在图像识别和语音识别中打破记录外，它还在预测潜在药物分子活动、分析粒子加速器数据、重建脑回路和预测非编码DNA突变对基因表达和疾病的影响方面击败了其他机器学习技术。也许更令人惊讶的是，深度学习为自然语言理解的各种任务，特别是专题分类、情感分析、答题和语言翻译产生了极具希望的结果。

我们认为，深度学习在不久的将来将有更多的成功，因为它需要的工程很少，因此它可以很容易地利用现有计算和数据数量的增加。目前正在为深层神经网络开发的新的学习算法和架构只会加速这一进展。

## 监督学习

机器学习最常见的形式，无论是否深度，都是监督学习。想象一下，我们想要建立一个系统，可以将图像分类，例如，包含一所房子、一辆汽车、一个人或一只宠物。我们首先收集了大量的数据，包括房屋、汽车、人和宠物的图像，每一个图像都标有其类别。在训练过程中，机器被给予一个图像，并以得分向量的形式生成输出，每个类别一个。们希望理想的类别在所有类别中得分最高，但在训练前不可能做到这一点。我们设计一个目标函数来测量输出分数和期望分数之间的误差（或偏差）。然后，机器修改其内部可调参数，以减少此误差。这些可调参数（通常称为权重）是实数，可以看作是定义机器输入-输出功能的“旋钮”。在一个典型的深度学习系统中，可能有数以亿计的可调重量和数以亿计的标记示例来训练机器。为了适当调整权值向量，学习算法计算了一个梯度向量，对于每个权值，该梯度向量指示如果权值增加少量，误差会增加或减少多少。然后按与梯度向量相反的方向调整权重向量。

目标函数在所有训练实例中取平均值，可以看作是高维权重空间中的一个山丘。负梯度向量指示该地形中最陡的下降方向，使目标函数更接近最小值，在这里的输出误差低于平均值。在实践中，大多数实践者使用一种称为随机梯度下降（sgd）的方法。这包括x给予几个样本的输入向量，计算输出和误差，计算这些样本的平均梯度，并相应地调整权重。这个过程对训练集中的许多小例子重复，直到目标函数的平均值停止下降。它之所以被称为随机，是因为每个小样本集都给出了所有样本平均梯度的噪声估计。在训练之后，系统的性能是通过另一组称为测试集的样本来测量的。这是为了测试机器的泛化能力，它能够在训练中从未见过的新输入上生成合理的答案。目前机器学习的许多实际应用都是在手工设计的特征之上使用线性分类器。两类线性分类器计算特征向量分量的加权和。如果加权和高于阈值，则将输入分类为属于特定类别。自20世纪60年代以来，我们就知道线性分类器只能将输入空间划分为非常简单的区域，即由超平面分离的半空间。但是像图像和语音识别这样的问题要求输入输出函数对输入的不相关的变化不敏感，比如物体的位置、方向或亮度的变化，或者语音的音调或口音的变化，同时对特定的细微的变化非常敏感（例如，白狼和一种名为萨摩耶的狼样白狗之间的区别）。在像素水平上，两个处于不同姿势和不同环境下的样本图像可能截然不同，而在相同位置和相似背景下的萨摩耶和狼的图像可能非常相似。线性分类器，或任何其他‘浅度分类器‘运行在：

- 一个多层神经网络（由连接的点表示）可以扭曲输入空间，使数据类（例如在红蓝线上）线性分离。请注意，输入空间中的规则网格（如左图所示）是如何被隐藏单元转换的（如中间图片所示）。这是一个只有两个输入单元、两个隐藏单元和一个输出单元的示例，但是用于图像识别或自然语言处理的网络包含几万或几十万个单元
- 导数的链式法则告诉我们如何组成两个小效应（x对y的小变化和y对z的小变化）。通过乘以 ∂y/∂x（即偏导数的定义），x 中的微小变化 Δx 首先转化为 y 中的微小变化 Δy。类似地，变化Δy在z中产生变化Δz。将一个方程代入另一个方程给出了导数的链式规则-如何通过乘以 ∂y/∂x 和 ∂z/∂x 的乘积将Δx转化为z。当x，y和z是向量（导数是雅可比矩阵）时，它也可以工作。
- 用于计算神经网络中正向通过的方程，其中有两个隐藏层和一个输出层，每个输出层构成一个模块，通过该模块可以反向传播梯度。在每一层，我们首先计算每个单元的总输入z，这是低一层单元输出的加权和。然后将非线性函数 f(.) 应用于 z，得到单元的输出。为了简单起见，我们省略了偏置项。神经网络中使用的非线性函数包括近年来常用的整流线性单元（ReLU）$f(z) = max(0, z)$ ，以及更为常规的 $sigmoid$ ，还有混合切线 $f(z) = (e^z − e^{−z})/(e^z + e^{−z}) $ 、logistic 函数 $f(z) = 1/(1 + exp(−z))$。

![](/assets/images/posts/2019-09-04-nature.deep.review/1.png)

